# ğŸ¤– Kokoro Conversational AI

A complete conversational AI system that combines **Ollama (Llama 3.2)** with **GPU-accelerated Kokoro TTS** for natural conversations with voice synthesis.

## âœ¨ Features

- **ğŸ§  Smart Conversations**: Powered by Llama 3.2 via Ollama
- **ğŸ¤ Natural Voice**: GPU-accelerated Kokoro TTS with 25+ voices
- **ğŸŒ Web Interface**: Modern, responsive chat interface
- **ğŸ’¬ CLI Mode**: Terminal-based conversational experience
- **ğŸ”„ Context Awareness**: Maintains conversation history and context
- **âš¡ High Performance**: Sub-second TTS generation with model preloading
- **ğŸ“Š Statistics**: Real-time performance metrics and conversation analytics
- **ğŸ’¾ Conversation Export**: Save and load conversation histories

## ğŸš€ Quick Start

### 1. Start Ollama (Required)

Make sure Ollama is running with Llama 3.2:

```bash
# Start Ollama service
ollama serve

# In another terminal, ensure Llama 3.2 is available
ollama list
```

### 2. Launch Conversational AI

**Option A: Web Interface (Recommended)**
```bash
# Using batch file
start_conversational_ai.bat

# Or using PowerShell
.\start_conversational_ai.ps1

# Or manually
.venv\Scripts\python.exe conversational_web.py
```

Access at: **http://localhost:5002**

**Option B: CLI Mode**
```bash
.venv\Scripts\python.exe conversational_ai.py
```

## ğŸ­ Available Voices

### ğŸ‡ºğŸ‡¸ English (US) - Female
- **af_sarah**: Sarah (Professional, Clear) â­ *Default*
- **af_bella**: Bella (Warm, Friendly)
- **af_nova**: Nova (Energetic, Young)
- **af_jessica**: Jessica (Mature, Wise)
- **af_river**: River (Soft, Gentle)
- **af_sky**: Sky (Bright, Cheerful)

### ğŸ‡ºğŸ‡¸ English (US) - Male
- **am_adam**: Adam (Deep, Confident)
- **am_liam**: Liam (Young, Casual)
- **am_michael**: Michael (Professional, Clear)
- **am_eric**: Eric (Friendly, Approachable)
- **am_echo**: Echo (Mysterious, Dramatic)
- **am_onyx**: Onyx (Strong, Authoritative)

### ğŸ‡¬ğŸ‡§ English (GB)
- **bf_alice**: Alice (British, Elegant)
- **bf_emma**: Emma (British, Warm)
- **bm_daniel**: Daniel (British, Gentleman)
- **bm_george**: George (British, Distinguished)

## ğŸŒ Web Interface Features

### Chat Interface
- **Real-time messaging** with AI responses
- **Audio playback** of AI responses (auto-play toggle)
- **Voice selection** with live preview
- **Typing indicators** and status monitoring
- **Responsive design** for desktop and mobile

### Controls Panel
- **Voice changer**: Switch between 25+ voices instantly
- **Auto-play toggle**: Enable/disable automatic audio playback
- **Clear conversation**: Reset chat history
- **Save conversation**: Export chat to JSON file
- **Real-time statistics**: Response times, message counts, etc.

### Performance Metrics
- **AI Response Time**: How long Llama takes to generate text
- **TTS Generation Time**: GPU-accelerated speech synthesis time
- **Total Response Time**: End-to-end conversation latency
- **Average Performance**: Running statistics across conversation

## ğŸ’¬ CLI Mode Commands

When using the terminal interface:

```bash
# Chat normally
You: Hello, how are you today?

# Special commands
voice <name>     # Change TTS voice (e.g., "voice am_adam")
voices           # List all available voices
stats           # Show conversation statistics  
save            # Save conversation to JSON
mute            # Toggle audio playback on/off
quit/exit       # End conversation and save
```

## âš¡ Performance Optimization

### GPU Acceleration Status
- âœ… **TTS Model Preloaded**: Instant voice generation
- âœ… **GPU Memory Optimized**: ~400MB GPU RAM usage
- âœ… **Fallback System**: CLI fallback if direct API fails
- âš ï¸ **CUDA Libraries**: Some warnings present but system functional

### Typical Performance (RTX 4090)
- **AI Response**: ~2.0-3.0s (depends on response complexity)
- **TTS Generation**: ~0.6s (with preloaded model)
- **Total Response**: ~2.6-3.6s (including audio generation)

## ğŸ”§ Configuration

### Environment Variables
```bash
# GPU acceleration (automatically set)
ONNX_PROVIDER=CUDAExecutionProvider
```

### Ollama Settings
- **Default Model**: `llama3.2:latest`
- **Host**: `http://localhost:11434`
- **Context Window**: Maintains last 10 messages for context

### TTS Settings
- **Default Voice**: `af_sarah` (Sarah - Professional, Clear)
- **Sample Rate**: 24kHz
- **Audio Format**: WAV (uncompressed)
- **Speed**: 1.0x (adjustable in code)

## ğŸ“ File Structure

```
kokoro/
â”œâ”€â”€ conversational_ai.py      # CLI conversational interface
â”œâ”€â”€ conversational_web.py     # Web interface Flask app
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ chat.html             # Web chat interface
â”œâ”€â”€ temp_conversations/       # Audio files and conversation exports
â”œâ”€â”€ start_conversational_ai.bat  # Windows launcher
â”œâ”€â”€ start_conversational_ai.ps1  # PowerShell launcher
â””â”€â”€ CONVERSATIONAL_AI.md      # This documentation
```

## ğŸ¯ Usage Examples

### Web Interface
1. Open http://localhost:5002
2. Select your preferred voice from the dropdown
3. Type a message and press Enter
4. Listen to the AI's response with synthesized speech
5. Toggle auto-play, change voices, or save conversations as needed

### CLI Interface
```
ğŸ‘¤ You: What's the weather like today?
ğŸ¤– AI (2.1s): I don't have access to real-time weather data, but I'd be happy to discuss...
ğŸ¤ Generating speech...
âœ… Speech generated (0.6s)
ğŸ”Š Playing audio...
â±ï¸ (AI: 2.1s, TTS: 0.6s, Total: 2.7s)
```

## ğŸ” Troubleshooting

### Ollama Connection Issues
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Start Ollama if not running
ollama serve

# Verify Llama 3.2 is available
ollama list
```

### TTS Generation Issues
- **Direct API Errors**: System automatically falls back to CLI method
- **CUDA Warnings**: Non-fatal, GPU acceleration still functional
- **Audio Playback**: Check system volume and audio device settings

### Web Interface Issues
```bash
# Check if port 5002 is available
netstat -an | findstr :5002

# Access logs in terminal running conversational_web.py
```

## ğŸ“ˆ Future Enhancements

### Planned Features
- **ğŸµ Voice Cloning**: Custom voice training from audio samples
- **ğŸŒ Multi-language Support**: Expand beyond English voices
- **ğŸ”Š Voice Mixing**: Blend multiple voices for unique sounds
- **ğŸ“± Mobile App**: Native mobile application
- **ğŸ® Interactive Modes**: Gaming, storytelling, educational modes

### Advanced Integration
- **ğŸ“š RAG Support**: Document-based conversations
- **ğŸ¨ Visual Responses**: Image generation integration
- **ğŸ”— API Endpoints**: RESTful API for external integrations
- **ğŸ‘¥ Multi-user**: Concurrent conversation support

---

## ğŸ‰ Enjoy Your Conversational AI!

You now have a powerful conversational AI system that combines the intelligence of Llama 3.2 with the natural-sounding voice of Kokoro TTS, all optimized for your RTX 4090 GPU.

**Start chatting and experience the future of human-AI interaction! ğŸš€**