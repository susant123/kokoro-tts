<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ðŸ¤– AI Chat</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <style>
        body {
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            min-height: 100vh;
        }
        
        .chat-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .chat-header {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 20px;
            margin-bottom: 20px;
            color: white;
            text-align: center;
        }
        
        .chat-main {
            display: grid;
            grid-template-columns: 1fr 300px;
            gap: 20px;
        }
        
        .chat-messages {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 15px;
            padding: 20px;
            height: 600px;
            overflow-y: auto;
            display: flex;
            flex-direction: column;
        }
        
        .chat-controls {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 15px;
            padding: 20px;
            height: fit-content;
        }
        
        .message {
            margin-bottom: 15px;
            padding: 12px 16px;
            border-radius: 18px;
            max-width: 80%;
            position: relative;
        }
        
        .message.user {
            background: #007bff;
            color: white;
            align-self: flex-end;
            margin-left: auto;
        }
        
        .message.assistant {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            align-self: flex-start;
        }
        
        /* AI Response Formatting Styles */
        .ai-content {
            line-height: 1.6;
        }
        
        .ai-content h1, .ai-content h2, .ai-content h3, 
        .ai-content h4, .ai-content h5, .ai-content h6 {
            margin-top: 16px;
            margin-bottom: 8px;
            font-weight: bold;
            color: #2c3e50;
        }
        
        .ai-content h1 { font-size: 1.5em; border-bottom: 2px solid #3498db; padding-bottom: 4px; }
        .ai-content h2 { font-size: 1.3em; color: #2980b9; }
        .ai-content h3 { font-size: 1.2em; color: #34495e; }
        
        .ai-content p {
            margin-bottom: 12px;
        }
        
        .ai-content ul, .ai-content ol {
            margin: 10px 0;
            padding-left: 20px;
        }
        
        .ai-content li {
            margin-bottom: 4px;
        }
        
        .ai-content blockquote {
            border-left: 4px solid #3498db;
            padding-left: 12px;
            margin: 12px 0;
            background: rgba(52, 152, 219, 0.1);
            border-radius: 0 4px 4px 0;
        }
        
        .ai-content code {
            background: #f1f2f6;
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            color: #e74c3c;
        }
        
        .ai-content pre {
            background: #2c3e50;
            color: #ecf0f1;
            padding: 12px;
            border-radius: 6px;
            overflow-x: auto;
            margin: 12px 0;
        }
        
        .ai-content pre code {
            background: none;
            color: inherit;
            padding: 0;
        }
        
        .ai-content strong, .ai-content b {
            font-weight: bold;
            color: #2c3e50;
        }
        
        .ai-content em, .ai-content i {
            font-style: italic;
            color: #7f8c8d;
        }
        
        .ai-content a {
            color: #3498db;
            text-decoration: none;
        }
        
        .ai-content a:hover {
            text-decoration: underline;
        }
        
        .ai-content table {
            width: 100%;
            border-collapse: collapse;
            margin: 12px 0;
        }
        
        .ai-content th, .ai-content td {
            border: 1px solid #bdc3c7;
            padding: 8px 12px;
            text-align: left;
        }
        
        .ai-content th {
            background: #ecf0f1;
            font-weight: bold;
        }
        
        .ai-content hr {
            border: none;
            height: 2px;
            background: linear-gradient(to right, #3498db, transparent);
            margin: 20px 0;
        }
        
        .message-audio {
            margin-top: 8px;
        }
        
        .message-time {
            font-size: 0.7em;
            opacity: 0.7;
            margin-top: 5px;
        }
        
        .typing-indicator {
            display: none;
            align-self: flex-start;
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 18px;
            padding: 12px 16px;
            margin-bottom: 15px;
        }
        
        .typing-dots {
            display: inline-flex;
            gap: 4px;
        }
        
        .typing-dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: #6c757d;
            animation: typing 1.4s infinite ease-in-out;
        }
        
        .typing-dot:nth-child(1) { animation-delay: -0.32s; }
        .typing-dot:nth-child(2) { animation-delay: -0.16s; }
        
        @keyframes typing {
            0%, 80%, 100% { transform: scale(0); opacity: 0.5; }
            40% { transform: scale(1); opacity: 1; }
        }
        
        .chat-input-container {
            position: relative;
            margin-top: 20px;
        }
        
        .chat-input {
            border-radius: 25px;
            padding-right: 60px;
        }
        
        .send-button {
            position: absolute;
            right: 5px;
            top: 50%;
            transform: translateY(-50%);
            border-radius: 50%;
            width: 40px;
            height: 40px;
            border: none;
            background: #007bff;
            color: white;
        }
        
        .send-button:hover {
            background: #0056b3;
        }
        
        .status-indicator {
            display: inline-flex;
            align-items: center;
            gap: 5px;
            font-size: 0.9em;
        }
        
        .status-dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
        }
        
        .status-online { background: #28a745; }
        .status-offline { background: #dc3545; }
        .status-warning { background: #ffc107; }
        
        .voice-selector {
            margin-bottom: 15px;
        }
        
        .stats-panel {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 15px;
            margin-top: 15px;
        }
        
        .stats-item {
            display: flex;
            justify-content: space-between;
            margin-bottom: 5px;
        }
        
        /* Speech Recognition Styles */
        .speech-controls {
            margin-bottom: 15px;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 10px;
            border: 1px solid #dee2e6;
        }
        
        .mic-button {
            width: 60px;
            height: 60px;
            border-radius: 50%;
            border: none;
            font-size: 1.5rem;
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
        }
        
        .mic-button:not(.listening):not(.processing) {
            background: #28a745;
            color: white;
        }
        
        .mic-button:not(.listening):not(.processing):hover {
            background: #20c997;
            transform: scale(1.05);
        }
        
        .mic-button.listening {
            background: #dc3545;
            color: white;
            animation: pulse 2s infinite;
        }
        
        .mic-button.processing {
            background: #ffc107;
            color: white;
        }
        
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(220, 53, 69, 0.7); }
            50% { box-shadow: 0 0 0 15px rgba(220, 53, 69, 0); }
            100% { box-shadow: 0 0 0 0 rgba(220, 53, 69, 0); }
        }
        
        .transcript-display {
            background: white;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 10px;
            margin-top: 10px;
            min-height: 40px;
            font-style: italic;
            color: #6c757d;
        }
        
        .transcript-display.active {
            border-color: #007bff;
            color: #000;
            font-style: normal;
        }
        
        .speech-status {
            text-align: center;
            margin-top: 10px;
            font-size: 0.9rem;
            color: #6c757d;
        }
        
        .speech-status.listening {
            color: #dc3545;
            font-weight: bold;
        }
        
        .speech-status.processing {
            color: #ffc107;
            font-weight: bold;
        }
        
        /* Context Section Styles */
        .context-active {
            border-left: 4px solid #28a745;
            background: rgba(40, 167, 69, 0.1);
        }
        
        .context-indicator {
            position: absolute;
            top: 10px;
            right: 10px;
            background: #28a745;
            color: white;
            padding: 2px 8px;
            border-radius: 12px;
            font-size: 0.7rem;
            font-weight: bold;
        }
        
        #context-input {
            resize: vertical;
            min-height: 80px;
        }
        
        @media (max-width: 768px) {
            .chat-main {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="chat-container">
        <!-- Header -->
        <div class="chat-header">
            <h1><i class="fas fa-robot"></i> AI Chat</h1>
            <p class="mb-0">
                Conversational AI with <strong>Llama 3.2</strong> + GPU-accelerated TTS
                <span id="status-indicator" class="status-indicator ms-3">
                    <span class="status-dot status-warning"></span>
                    <span>Connecting...</span>
                </span>
            </p>
        </div>
        
        <!-- Background Audio for Bluetooth Headphone Connection -->
        <audio id="background-audio" loop preload="auto" style="display: none;">
            <source src="/static/background_audio.wav" type="audio/wav">
        </audio>
        
        <!-- Main Chat Area -->
        <div class="chat-main">
            <!-- Messages -->
            <div class="card">
                <div class="card-body p-0">
                    <div id="chat-messages" class="chat-messages">
                        <div class="message assistant">
                            <strong>ðŸ¤– AI:</strong> Hello! I'm ready to chat. I can discuss any topic and respond with natural-sounding speech. What would you like to talk about?
                        </div>
                        
                        <!-- Typing indicator -->
                        <div id="typing-indicator" class="typing-indicator">
                            <i class="fas fa-robot me-2"></i>
                            <span class="typing-dots">
                                <span class="typing-dot"></span>
                                <span class="typing-dot"></span>
                                <span class="typing-dot"></span>
                            </span>
                        </div>
                    </div>
                    
                    <!-- Input Area -->
                    <div class="chat-input-container">
                        <div class="input-group">
                            <input type="text" id="chat-input" class="form-control chat-input" 
                                   placeholder="Type your message here..." maxlength="1000">
                            <button id="send-button" class="send-button" title="Send message">
                                <i class="fas fa-paper-plane"></i>
                            </button>
                        </div>
                    </div>
                </div>
            </div>
            
            <!-- Controls Panel -->
            <div class="chat-controls">
                <h5><i class="fas fa-cog"></i> Controls</h5>
                
                <!-- Speech Recognition -->
                <div class="speech-controls">
                    <h6><i class="fas fa-microphone"></i> Voice Input</h6>
                    <div class="text-center">
                        <button id="mic-button" class="mic-button" title="Click to start voice input">
                            <i class="fas fa-microphone"></i>
                        </button>
                    </div>
                    <div id="transcript-display" class="transcript-display">
                        Click microphone â†’ speak â†’ pause 2 seconds to send
                    </div>
                    <div id="speech-status" class="speech-status">
                        Ready for voice input
                    </div>
                    <div class="mt-2">
                        <div class="form-check form-check-inline">
                            <input class="form-check-input" type="checkbox" id="auto-send-speech" checked>
                            <label class="form-check-label" for="auto-send-speech">
                                Auto-send speech
                            </label>
                        </div>
                        <div class="form-check form-check-inline">
                            <input class="form-check-input" type="checkbox" id="continuous-listening">
                            <label class="form-check-label" for="continuous-listening">
                                Continuous mode
                            </label>
                        </div>
                    </div>
                </div>
                
                <!-- Context Input -->
                <div class="mb-3">
                    <div class="d-flex align-items-center justify-content-between mb-2">
                        <label class="form-label mb-0">
                            <i class="fas fa-brain"></i> AI Context
                        </label>
                        <button id="toggle-context" class="btn btn-outline-secondary btn-sm">
                            <i class="fas fa-chevron-down"></i>
                        </button>
                    </div>
                    <div id="context-section" class="collapse">
                        <textarea id="context-input" class="form-control mb-2" rows="4" 
                                  placeholder="Set the AI's role and behavior... 
Examples:
â€¢ You are a Java senior developer interviewer. Ask me challenging technical questions.
â€¢ Act as an HR interviewer and provide feedback on my responses.
â€¢ You are a helpful coding mentor for Python beginners."></textarea>
                        <div class="d-flex gap-2">
                            <button id="apply-context" class="btn btn-primary btn-sm">
                                <i class="fas fa-check"></i> Apply Context
                            </button>
                            <button id="clear-context" class="btn btn-outline-warning btn-sm">
                                <i class="fas fa-times"></i> Clear
                            </button>
                        </div>
                        <div id="context-status" class="mt-2 small text-muted">
                            No context set
                        </div>
                    </div>
                </div>

                <!-- Voice Selector -->
                <div class="voice-selector">
                    <label for="voice-select" class="form-label">
                        <i class="fas fa-microphone"></i> TTS Voice
                    </label>
                    <select id="voice-select" class="form-select">
                        <option value="">Loading voices...</option>
                    </select>
                </div>
                
                <!-- Background Audio Controls -->
                <div class="mb-3">
                    <label for="bg-volume" class="form-label">
                        <i class="fas fa-music"></i> Background Audio
                    </label>
                    <div class="d-flex gap-2 align-items-center mb-2">
                        <button id="toggle-bg-audio" class="btn btn-outline-secondary btn-sm">
                            <i class="fas fa-music"></i> Enable BG Music
                        </button>
                    </div>
                    <input type="range" id="bg-volume" class="form-range" min="0" max="20" value="5" 
                           title="Background music volume (keeps Bluetooth connected)">
                    <small class="text-muted">Keeps Bluetooth headphones connected</small>
                </div>
                
                <!-- Action Buttons -->
                <div class="d-grid gap-2">
                    <button id="clear-chat" class="btn btn-outline-warning">
                        <i class="fas fa-trash"></i> Clear Chat
                    </button>
                    <button id="save-chat" class="btn btn-outline-primary">
                        <i class="fas fa-save"></i> Save Conversation
                    </button>
                    <button id="toggle-auto-play" class="btn btn-outline-success">
                        <i class="fas fa-volume-up"></i> Auto-play: ON
                    </button>
                    <button id="toggle-streaming" class="btn btn-outline-primary">
                        <i class="fas fa-stream"></i> Streaming: ON
                    </button>
                    <button id="test-audio" class="btn btn-outline-info">
                        <i class="fas fa-play"></i> Test Audio
                    </button>
                    <button id="stop-audio" class="btn btn-outline-danger">
                        <i class="fas fa-stop"></i> Stop Audio
                    </button>
                </div>
                
                <!-- Stats Panel -->
                <div id="stats-panel" class="stats-panel">
                    <h6><i class="fas fa-chart-bar"></i> Statistics</h6>
                    <div class="stats-item">
                        <span>Messages:</span>
                        <span id="stat-messages">0</span>
                    </div>
                    <div class="stats-item">
                        <span>AI Responses:</span>
                        <span id="stat-ai-responses">0</span>
                    </div>
                    <div class="stats-item">
                        <span>Avg Response:</span>
                        <span id="stat-avg-time">0.0s</span>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script>
        class KokoroChat {
            constructor() {
                this.messagesContainer = document.getElementById('chat-messages');
                this.chatInput = document.getElementById('chat-input');
                this.sendButton = document.getElementById('send-button');
                this.typingIndicator = document.getElementById('typing-indicator');
                this.statusIndicator = document.getElementById('status-indicator');
                this.voiceSelect = document.getElementById('voice-select');
                
                // Background audio elements
                this.backgroundAudio = document.getElementById('background-audio');
                this.bgVolumeSlider = document.getElementById('bg-volume');
                this.toggleBgButton = document.getElementById('toggle-bg-audio');
                
                // Speech recognition elements
                this.micButton = document.getElementById('mic-button');
                this.transcriptDisplay = document.getElementById('transcript-display');
                this.speechStatus = document.getElementById('speech-status');
                this.autoSendSpeech = document.getElementById('auto-send-speech');
                this.continuousListening = document.getElementById('continuous-listening');
                
                // Context elements
                this.contextInput = document.getElementById('context-input');
                this.contextSection = document.getElementById('context-section');
                this.toggleContextButton = document.getElementById('toggle-context');
                this.applyContextButton = document.getElementById('apply-context');
                this.clearContextButton = document.getElementById('clear-context');
                this.contextStatus = document.getElementById('context-status');
                
                this.autoPlay = true;
                this.bgMusicEnabled = false;
                this.responseTimes = [];
                this.currentContext = '';
                this.contextApplied = false;
                
                // Streaming audio support
                this.currentAudioQueue = [];
                this.isPlayingStream = false;
                this.streamingEnabled = true;
                this.currentAudioElement = null; // Track currently playing audio
                this.globalAudioQueue = []; // Global queue for all audio requests
                
                // Speech recognition setup
                this.speechRecognition = null;
                this.isListening = false;
                this.currentTranscript = '';
                
                this.initializeEventListeners();
                this.initializeBackgroundAudio();
                this.initializeSpeechRecognition();
                this.enableAudioContext(); // Enable audio context immediately
                this.loadVoices();
                this.checkStatus();
                
                // Force reset microphone button to default state
                this.resetMicrophoneButton();
                
                // Auto-scroll to bottom
                this.scrollToBottom();
            }
            
            initializeEventListeners() {
                // Send message
                this.sendButton.addEventListener('click', () => this.handleSendClick());
                this.chatInput.addEventListener('keypress', (e) => {
                    if (e.key === 'Enter' && !e.shiftKey) {
                        e.preventDefault();
                        this.handleSendClick();
                    }
                });
                
                // Voice change
                this.voiceSelect.addEventListener('change', () => this.changeVoice());
                
                // Control buttons
                document.getElementById('clear-chat').addEventListener('click', () => this.clearChat());
                document.getElementById('save-chat').addEventListener('click', () => this.saveChat());
                document.getElementById('toggle-auto-play').addEventListener('click', () => this.toggleAutoPlay());
                document.getElementById('toggle-streaming').addEventListener('click', () => this.toggleStreaming());
                document.getElementById('test-audio').addEventListener('click', () => this.testAudio());
                document.getElementById('stop-audio').addEventListener('click', () => this.stopAllAudio());
                
                // Background audio controls
                this.toggleBgButton.addEventListener('click', () => this.toggleBackgroundAudio());
                this.bgVolumeSlider.addEventListener('input', () => this.updateBackgroundVolume());
                
                // Speech recognition controls
                this.micButton.addEventListener('click', () => this.toggleSpeechRecognition());
                this.continuousListening.addEventListener('change', () => this.updateContinuousMode());
                
                // Context controls
                this.toggleContextButton.addEventListener('click', () => this.toggleContextSection());
                this.applyContextButton.addEventListener('click', () => this.applyContext());
                this.clearContextButton.addEventListener('click', () => this.clearContext());
            }
            
            handleSendClick() {
                // If there's no text in the input but we have a current transcript from speech,
                // use the speech transcript
                if (!this.chatInput.value.trim() && this.currentTranscript) {
                    console.log('Using captured speech transcript for manual send:', this.currentTranscript);
                    this.chatInput.value = this.currentTranscript;
                }
                
                this.sendMessage();
            }
            
            async sendMessage() {
                const message = this.chatInput.value.trim();
                if (!message) return;
                
                // Add user message
                this.addMessage('user', message);
                this.chatInput.value = '';
                this.chatInput.disabled = true;
                this.sendButton.disabled = true;
                
                // Show typing indicator
                this.showTypingIndicator();
                
                let messageWasSentFromSpeech = (this.currentTranscript && message === this.currentTranscript);
                
                try {
                    const requestBody = { 
                        message: message,
                        streaming: this.streamingEnabled 
                    };
                    if (this.contextApplied && this.currentContext) {
                        requestBody.context = this.currentContext;
                    }
                    
                    const response = await fetch('/api/chat', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(requestBody)
                    });
                    
                    const data = await response.json();
                    
                    if (data.success) {
                        // Handle streaming vs regular response
                        if (data.streaming && data.audio_chunks) {
                            console.log('ðŸš€ Received streaming response with', data.audio_chunks.length, 'chunks');
                            console.log('ðŸ“Š Streaming data:', {
                                chunks: data.audio_chunks.length,
                                timing: data.timing,
                                autoPlay: this.autoPlay,
                                streamingEnabled: this.streamingEnabled
                            });
                            
                            this.addMessage('assistant', data.ai_response, null, data.timing);
                            this.handleStreamingAudio(data.audio_chunks, data.timing);
                        } else {
                            console.log('ðŸ“ž Received regular response');
                            this.addMessage('assistant', data.ai_response, data.audio_file, data.timing);
                        }
                        
                        this.updateStats(data.timing);
                        
                        // Clear speech buffers only after successful message send from speech
                        if (messageWasSentFromSpeech) {
                            this.clearSpeechBuffers();
                        }
                    } else {
                        this.addMessage('system', `Error: ${data.error}`, null, null, 'text-danger');
                    }
                    
                } catch (error) {
                    this.addMessage('system', `Connection error: ${error.message}`, null, null, 'text-danger');
                } finally {
                    this.hideTypingIndicator();
                    this.chatInput.disabled = false;
                    this.sendButton.disabled = false;
                    this.chatInput.focus();
                }
            }
            
            addMessage(role, content, audioFile = null, timing = null, extraClass = '') {
                const messageDiv = document.createElement('div');
                messageDiv.className = `message ${role} ${extraClass}`;
                
                let html = '';
                
                if (role === 'user') {
                    html = `<strong>ðŸ‘¤ You:</strong> ${this.escapeHtml(content)}`;
                } else if (role === 'assistant') {
                    const formattedContent = this.formatAiResponse(content);
                    html = `<strong>ðŸ¤– AI:</strong><div class="ai-content">${formattedContent}</div>`;
                } else {
                    html = content;
                }
                
                if (timing) {
                    html += `<div class="message-time">
                        <i class="fas fa-clock"></i> AI: ${timing.ai_time.toFixed(1)}s, 
                        TTS: ${timing.tts_time.toFixed(1)}s, 
                        Total: ${timing.total_time.toFixed(1)}s
                    </div>`;
                }
                
                messageDiv.innerHTML = html;
                
                // Add audio player if available
                if (audioFile && this.autoPlay) {
                    // Stop any currently playing audio first
                    this.stopAllAudio();
                    
                    const audioDiv = document.createElement('div');
                    audioDiv.className = 'message-audio';
                    audioDiv.innerHTML = `
                        <audio controls autoplay style="width: 100%; max-width: 300px;">
                            <source src="/audio/${audioFile}" type="audio/wav">
                        </audio>
                    `;
                    messageDiv.appendChild(audioDiv);
                    
                    // Track this audio element for stopping if needed
                    const audioElement = audioDiv.querySelector('audio');
                    if (audioElement) {
                        this.currentAudioElement = audioElement;
                        
                        audioElement.onplay = () => {
                            this.updateAudioControls();
                        };
                        
                        audioElement.onended = () => {
                            if (this.currentAudioElement === audioElement) {
                                this.currentAudioElement = null;
                                this.updateAudioControls();
                            }
                        };
                        
                        audioElement.onpause = () => {
                            this.updateAudioControls();
                        };
                    }
                }
                
                this.messagesContainer.appendChild(messageDiv);
                this.scrollToBottom();
            }
            
            showTypingIndicator() {
                this.typingIndicator.style.display = 'flex';
                this.scrollToBottom();
            }
            
            hideTypingIndicator() {
                this.typingIndicator.style.display = 'none';
            }
            
            scrollToBottom() {
                setTimeout(() => {
                    this.messagesContainer.scrollTop = this.messagesContainer.scrollHeight;
                }, 100);
            }
            
            async loadVoices() {
                try {
                    const response = await fetch('/api/voices');
                    const data = await response.json();
                    
                    if (data.success) {
                        this.voiceSelect.innerHTML = '';
                        
                        for (const [voice, description] of Object.entries(data.voices)) {
                            const option = document.createElement('option');
                            option.value = voice;
                            option.textContent = description;
                            option.selected = voice === data.current_voice;
                            this.voiceSelect.appendChild(option);
                        }
                    }
                } catch (error) {
                    console.error('Failed to load voices:', error);
                }
            }
            
            async changeVoice() {
                const voice = this.voiceSelect.value;
                if (!voice) return;
                
                try {
                    const response = await fetch('/api/voice', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ voice: voice })
                    });
                    
                    const data = await response.json();
                    
                    if (data.success) {
                        this.addMessage('system', `ðŸŽ¤ Voice changed to: ${data.message.replace('Voice changed to ', '')}`, null, null, 'text-info');
                    }
                } catch (error) {
                    console.error('Failed to change voice:', error);
                }
            }
            
            async clearChat() {
                if (!confirm('Are you sure you want to clear the chat history?')) return;
                
                try {
                    const response = await fetch('/api/clear');
                    const data = await response.json();
                    
                    if (data.success) {
                        this.messagesContainer.innerHTML = `
                            <div class="message assistant">
                                <strong>ðŸ¤–  AI:</strong> Chat history cleared. How can I help you?
                            </div>
                            <div id="typing-indicator" class="typing-indicator">
                                <i class="fas fa-robot me-2"></i>
                                <span class="typing-dots">
                                    <span class="typing-dot"></span>
                                    <span class="typing-dot"></span>
                                    <span class="typing-dot"></span>
                                </span>
                            </div>
                        `;
                        this.typingIndicator = document.getElementById('typing-indicator');
                        this.responseTimes = [];
                        this.updateStatsDisplay();
                        
                        // Also clear context when chat is cleared
                        this.clearContext();
                        
                        // Reset microphone button state
                        this.resetMicrophoneButton();
                    }
                } catch (error) {
                    console.error('Failed to clear chat:', error);
                }
            }
            
            async saveChat() {
                try {
                    const response = await fetch('/api/save');
                    const data = await response.json();
                    
                    if (data.success) {
                        this.addMessage('system', `ðŸ’¾ ${data.message}`, null, null, 'text-success');
                    }
                } catch (error) {
                    console.error('Failed to save chat:', error);
                }
            }
            
            toggleAutoPlay() {
                this.autoPlay = !this.autoPlay;
                const button = document.getElementById('toggle-auto-play');
                const icon = button.querySelector('i');
                
                if (this.autoPlay) {
                    icon.className = 'fas fa-volume-up';
                    button.innerHTML = '<i class="fas fa-volume-up"></i> Auto-play: ON';
                    button.className = 'btn btn-outline-success';
                } else {
                    icon.className = 'fas fa-volume-mute';
                    button.innerHTML = '<i class="fas fa-volume-mute"></i> Auto-play: OFF';
                    button.className = 'btn btn-outline-secondary';
                }
            }
            
            handleStreamingAudio(audioChunks, timing) {
                if (!this.autoPlay || !audioChunks || audioChunks.length === 0) {
                    console.log('Streaming audio disabled or no chunks:', { autoPlay: this.autoPlay, chunks: audioChunks?.length });
                    return;
                }
                
                console.log('ðŸŽµ Handling streaming audio:', audioChunks.length, 'chunks');
                
                // Stop any currently playing audio to prevent overlap
                this.stopAllAudio();
                
                // Clear any existing audio queue
                this.currentAudioQueue = [];
                this.globalAudioQueue = [];
                this.isPlayingStream = false;
                
                // Sort chunks by chunk_id to ensure proper order
                const sortedChunks = [...audioChunks].sort((a, b) => a.chunk_id - b.chunk_id);
                console.log('ðŸ“‹ Sorted chunks:', sortedChunks.map(c => `${c.chunk_id}: ${c.audio_file}`));
                
                // Add chunks to queue
                this.currentAudioQueue = sortedChunks.map(chunk => ({
                    url: `/audio/${chunk.audio_file}`,
                    text: chunk.text,
                    duration: chunk.duration,
                    is_final: chunk.is_final,
                    chunk_id: chunk.chunk_id
                }));
                
                console.log('ðŸ”„ Audio queue prepared:', this.currentAudioQueue.length, 'items');
                
                // Start playing immediately
                this.playNextAudioChunk();
                
                // Show streaming info
                const firstChunkTime = timing.first_chunk_ready || 0;
                const totalTime = timing.total_time || 0;
                const streamingBenefit = totalTime - firstChunkTime;
                
                if (streamingBenefit > 0.5) {  // Only show if meaningful benefit
                    this.addMessage('system', 
                        `ðŸš€ Streaming enabled: First audio ready ${firstChunkTime.toFixed(1)}s faster (${streamingBenefit.toFixed(1)}s improvement)`, 
                        null, null, 'text-success small');
                }
            }
            
            playNextAudioChunk() {
                if (this.currentAudioQueue.length === 0) {
                    this.isPlayingStream = false;
                    this.currentAudioElement = null;
                    console.log('ðŸ Streaming audio complete - no more chunks');
                    return;
                }
                
                if (this.isPlayingStream) {
                    console.log('â³ Already playing stream, waiting for current chunk to finish...');
                    return;
                }
                
                this.isPlayingStream = true;
                const chunk = this.currentAudioQueue.shift();
                
                console.log('ðŸŽµ Playing audio chunk', chunk.chunk_id + ':', chunk.text.substring(0, 50) + '...');
                console.log('ðŸ”— Audio URL:', chunk.url);
                
                // Create and play audio element
                const audio = new Audio();
                this.currentAudioElement = audio; // Track current audio element
                
                // Set up event handlers before setting src
                audio.oncanplaythrough = () => {
                    // Double-check we should still be playing this audio (might have been stopped)
                    if (this.currentAudioElement !== audio) {
                        console.log('ðŸš« Chunk', chunk.chunk_id, 'cancelled - newer audio started');
                        return;
                    }
                    
                    console.log('âœ… Chunk', chunk.chunk_id, 'loaded and ready to play');
                    audio.play().then(() => {
                        console.log('â–¶ï¸ Chunk', chunk.chunk_id, 'playback started');
                        this.updateAudioControls(); // Update visual state
                    }).catch(e => {
                        console.error('âŒ Chunk', chunk.chunk_id, 'playback failed:', e);
                        this.isPlayingStream = false;
                        this.currentAudioElement = null;
                        this.playNextAudioChunk(); // Try next chunk
                    });
                };
                
                audio.onended = () => {
                    // Only process if this is still the current audio
                    if (this.currentAudioElement === audio) {
                        console.log('â¹ï¸ Chunk', chunk.chunk_id, 'playback ended');
                        this.isPlayingStream = false;
                        this.currentAudioElement = null;
                        this.updateAudioControls(); // Update visual state
                        
                        // Small gap between chunks for natural flow
                        setTimeout(() => {
                            this.playNextAudioChunk();
                        }, 150); // Slightly longer gap for better transitions
                    }
                };
                
                audio.onerror = (e) => {
                    console.error('âŒ Audio chunk', chunk.chunk_id, 'error:', e);
                    console.error('ðŸ”— Failed URL:', chunk.url);
                    
                    // Only process if this is still the current audio
                    if (this.currentAudioElement === audio) {
                        this.isPlayingStream = false;
                        this.currentAudioElement = null;
                        this.playNextAudioChunk(); // Try next chunk
                    }
                };
                
                audio.onloadstart = () => {
                    console.log('ðŸ”„ Loading chunk', chunk.chunk_id, 'from:', chunk.url);
                };
                
                audio.onloadeddata = () => {
                    console.log('ðŸ“ Chunk', chunk.chunk_id, 'data loaded');
                };
                
                // Set source URL to start loading
                audio.src = chunk.url;
                audio.load(); // Explicitly trigger loading
                
                // Fallback timeout in case events don't fire
                setTimeout(() => {
                    if (this.currentAudioElement === audio && this.isPlayingStream && audio.currentTime === 0 && audio.readyState < 3) {
                        console.warn('â° Audio chunk', chunk.chunk_id, 'timeout - readyState:', audio.readyState);
                        console.warn('ðŸ”— Timeout URL:', chunk.url);
                        this.isPlayingStream = false;
                        this.currentAudioElement = null;
                        this.playNextAudioChunk();
                    }
                }, Math.max(5000, (chunk.duration + 3) * 1000)); // At least 5 seconds or chunk duration + buffer
            }
            
            toggleStreaming() {
                this.streamingEnabled = !this.streamingEnabled;
                const button = document.getElementById('toggle-streaming');
                const icon = button.querySelector('i');
                
                if (this.streamingEnabled) {
                    icon.className = 'fas fa-stream';
                    button.innerHTML = '<i class="fas fa-stream"></i> Streaming: ON';
                    button.className = 'btn btn-outline-primary';
                    this.addMessage('system', 'ðŸš€ Streaming TTS enabled: Audio will play as chunks are ready', null, null, 'text-info');
                } else {
                    icon.className = 'fas fa-pause';
                    button.innerHTML = '<i class="fas fa-pause"></i> Streaming: OFF';
                    button.className = 'btn btn-outline-secondary';
                    this.addMessage('system', 'â¸ï¸ Streaming TTS disabled: Will use traditional single-file processing', null, null, 'text-info');
                }
            }
            
            testAudio() {
                console.log('ðŸ§ª Testing audio playback...');
                
                // Test with a simple beep first
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const oscillator = audioContext.createOscillator();
                const gainNode = audioContext.createGain();
                
                oscillator.connect(gainNode);
                gainNode.connect(audioContext.destination);
                
                oscillator.frequency.value = 800;
                gainNode.gain.setValueAtTime(0, audioContext.currentTime);
                gainNode.gain.linearRampToValueAtTime(0.1, audioContext.currentTime + 0.01);
                gainNode.gain.exponentialRampToValueAtTime(0.001, audioContext.currentTime + 0.2);
                
                oscillator.start(audioContext.currentTime);
                oscillator.stop(audioContext.currentTime + 0.2);
                
                console.log('ðŸ”Š Test beep played');
                this.addMessage('system', 'ðŸ§ª Audio test: Beep played. Check if you heard it.', null, null, 'text-info');
                
                // Also test if we can access the audio endpoint
                fetch('/api/status')
                    .then(response => response.json())
                    .then(data => {
                        console.log('ðŸ“¡ Server status check:', data);
                        this.addMessage('system', `ðŸ“¡ Server status: ${data.success ? 'Connected' : 'Issues detected'}`, null, null, data.success ? 'text-success' : 'text-warning');
                    })
                    .catch(e => {
                        console.error('ðŸ“¡ Server status check failed:', e);
                        this.addMessage('system', 'ðŸ“¡ Server connection: Failed to connect', null, null, 'text-danger');
                    });
            }
            
            stopAllAudio() {
                console.log('ðŸ›‘ Stopping all audio playback');
                
                // Stop current streaming audio
                if (this.currentAudioElement) {
                    console.log('ðŸ›‘ Stopping current audio element');
                    this.currentAudioElement.pause();
                    this.currentAudioElement.currentTime = 0;
                    this.currentAudioElement = null;
                }
                
                // Clear all audio queues
                this.currentAudioQueue = [];
                this.globalAudioQueue = [];
                this.isPlayingStream = false;
                
                // Stop any other audio elements that might be playing
                const audioElements = document.querySelectorAll('audio');
                audioElements.forEach(audio => {
                    if (!audio.paused) {
                        console.log('ðŸ›‘ Stopping audio element:', audio.src);
                        audio.pause();
                        audio.currentTime = 0;
                    }
                });
                
                // Stop background audio if it's playing
                if (this.backgroundAudio && !this.backgroundAudio.paused) {
                    // Don't stop background audio as it's meant to keep playing
                    console.log('ðŸŽµ Background audio continues (intentional)');
                }
                
                // Show user feedback
                this.addMessage('system', 'ðŸ›‘ All audio playback stopped', null, null, 'text-warning small');
                
                // Update stop button visual state
                this.updateAudioControls();
            }
            
            updateAudioControls() {
                const stopButton = document.getElementById('stop-audio');
                const isPlaying = this.isPlayingStream || (this.currentAudioElement && !this.currentAudioElement.paused);
                
                if (isPlaying) {
                    stopButton.className = 'btn btn-danger';
                    stopButton.innerHTML = '<i class="fas fa-stop"></i> Stop Playing';
                } else {
                    stopButton.className = 'btn btn-outline-danger';
                    stopButton.innerHTML = '<i class="fas fa-stop"></i> Stop Audio';
                }
            }
            
            resetMicrophoneButton() {
                console.log('ðŸŽ¤ Resetting microphone button to default state');
                if (this.micButton) {
                    this.micButton.classList.remove('listening', 'processing');
                    this.micButton.querySelector('i').className = 'fas fa-microphone';
                    this.micButton.title = 'Click to start voice input';
                }
                
                // Reset speech recognition state
                this.isListening = false;
                this.isManualStop = false;
                
                // Reset display
                if (this.transcriptDisplay) {
                    this.transcriptDisplay.textContent = 'Click microphone â†’ speak â†’ pause 2 seconds to send';
                    this.transcriptDisplay.classList.remove('active');
                }
                
                // Update status
                if (this.speechStatus) {
                    this.updateSpeechStatus('Ready for voice input');
                }
            }
            
            async checkStatus() {
                try {
                    const response = await fetch('/api/status');
                    const data = await response.json();
                    
                    if (data.success && data.ollama_connected) {
                        this.updateStatus('online', 'Connected');
                    } else {
                        this.updateStatus('offline', 'Ollama Offline');
                    }
                } catch (error) {
                    this.updateStatus('offline', 'Connection Failed');
                }
                
                // Check status every 30 seconds
                setTimeout(() => this.checkStatus(), 30000);
            }
            
            updateStatus(status, text) {
                const dot = this.statusIndicator.querySelector('.status-dot');
                const span = this.statusIndicator.querySelector('span:last-child');
                
                dot.className = `status-dot status-${status}`;
                span.textContent = text;
            }
            
            updateStats(timing) {
                this.responseTimes.push(timing.total_time);
                this.updateStatsDisplay();
            }
            
            updateStatsDisplay() {
                const totalMessages = document.querySelectorAll('.message.user').length;
                const aiResponses = document.querySelectorAll('.message.assistant').length;
                const avgTime = this.responseTimes.length > 0 
                    ? this.responseTimes.reduce((a, b) => a + b, 0) / this.responseTimes.length 
                    : 0;
                
                document.getElementById('stat-messages').textContent = totalMessages;
                document.getElementById('stat-ai-responses').textContent = aiResponses;
                document.getElementById('stat-avg-time').textContent = avgTime.toFixed(1) + 's';
            }
            
            // Context Management Methods
            toggleContextSection() {
                const isCollapsed = this.contextSection.classList.contains('show');
                
                if (isCollapsed) {
                    this.contextSection.classList.remove('show');
                    this.toggleContextButton.innerHTML = '<i class="fas fa-chevron-down"></i>';
                } else {
                    this.contextSection.classList.add('show');
                    this.toggleContextButton.innerHTML = '<i class="fas fa-chevron-up"></i>';
                }
            }
            
            applyContext() {
                const context = this.contextInput.value.trim();
                
                if (!context) {
                    this.addMessage('system', 'âš ï¸ Please enter a context before applying.', null, null, 'text-warning');
                    return;
                }
                
                this.currentContext = context;
                this.contextApplied = true;
                
                // Update UI
                this.updateContextStatus();
                this.addMessage('system', `ðŸ§  Context applied: "${context.substring(0, 100)}${context.length > 100 ? '...' : ''}"`, null, null, 'text-info');
                
                // Collapse the section
                this.contextSection.classList.remove('show');
                this.toggleContextButton.innerHTML = '<i class="fas fa-chevron-down"></i>';
            }
            
            clearContext() {
                this.currentContext = '';
                this.contextApplied = false;
                this.contextInput.value = '';
                
                // Update UI
                this.updateContextStatus();
                this.addMessage('system', 'ðŸ§  Context cleared. AI will use default behavior.', null, null, 'text-info');
            }
            
            updateContextStatus() {
                if (this.contextApplied && this.currentContext) {
                    this.contextStatus.textContent = `Active: "${this.currentContext.substring(0, 50)}${this.currentContext.length > 50 ? '...' : ''}"`;
                    this.contextStatus.className = 'mt-2 small text-success';
                    
                    // Add visual indicator to chat header
                    let indicator = document.querySelector('.context-indicator');
                    if (!indicator) {
                        indicator = document.createElement('div');
                        indicator.className = 'context-indicator';
                        document.querySelector('.chat-header').style.position = 'relative';
                        document.querySelector('.chat-header').appendChild(indicator);
                    }
                    indicator.textContent = 'CONTEXT ACTIVE';
                    
                } else {
                    this.contextStatus.textContent = 'No context set';
                    this.contextStatus.className = 'mt-2 small text-muted';
                    
                    // Remove visual indicator
                    const indicator = document.querySelector('.context-indicator');
                    if (indicator) {
                        indicator.remove();
                    }
                }
            }
            
            initializeBackgroundAudio() {
                // Set initial volume (very low)
                this.backgroundAudio.volume = 0.05; // 5% volume
                
                // Try to enable audio on first user interaction
                document.addEventListener('click', () => this.enableAudioContext(), { once: true });
                document.addEventListener('keydown', () => this.enableAudioContext(), { once: true });
            }
            
            enableAudioContext() {
                // Create a silent audio element to unlock autoplay policy
                const silentAudio = new Audio();
                silentAudio.src = 'data:audio/wav;base64,UklGRnoGAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YQoGAACBhYqFbF1fdJivrJBhNjVgodDbq2EcBj+a2/LDciUFLIHO8tiJNwgZaLvt559NEAxQp+PwtmMcBjiR1/LMeSwFJHfH8N2QQAoUXrTp66hVFApGn+DyvmwhBjy5Efj48+UbBiqNzO9zPwYMXL/o8cJ6KALHA9fywl+YSxcLUpjNx8p7JAIZacTu5pRECQ9jHfzK9tcXBy2G0fKqZBwOKKbmzWwBBQwgdcf6o2YaBR1uUf2xUAEODhBFJWYcBT3z4VZXDQlZYfCqZhsGJJ7n6dCGMQ8KSDcGdV4BBCJC5+DXfCgELY3X';
                silentAudio.volume = 0;
                silentAudio.play().then(() => {
                    console.log('ðŸ”“ Audio context unlocked for autoplay');
                }).catch(e => {
                    console.log('âš ï¸ Audio context unlock failed:', e);
                });
            }
            
            toggleBackgroundAudio() {
                this.bgMusicEnabled = !this.bgMusicEnabled;
                
                if (this.bgMusicEnabled) {
                    this.backgroundAudio.play().then(() => {
                        this.toggleBgButton.innerHTML = '<i class="fas fa-music"></i> BG Music: ON';
                        this.toggleBgButton.className = 'btn btn-success btn-sm';
                        this.addMessage('system', 'ðŸŽµ Background music enabled (keeps Bluetooth connected)', null, null, 'text-info');
                    }).catch(e => {
                        console.error('Failed to play background audio:', e);
                        this.addMessage('system', 'âš ï¸ Background music failed to start. Please try clicking again.', null, null, 'text-warning');
                        this.bgMusicEnabled = false;
                    });
                } else {
                    this.backgroundAudio.pause();
                    this.toggleBgButton.innerHTML = '<i class="fas fa-music"></i> Enable BG Music';
                    this.toggleBgButton.className = 'btn btn-outline-secondary btn-sm';
                    this.addMessage('system', 'ðŸ”‡ Background music disabled', null, null, 'text-info');
                }
            }
            
            updateBackgroundVolume() {
                const volume = this.bgVolumeSlider.value / 100; // Convert to 0-0.2 range
                this.backgroundAudio.volume = volume;
                
                // Show volume feedback
                const percentage = Math.round(volume * 100);
                this.bgVolumeSlider.title = `Background volume: ${percentage}% (keeps Bluetooth connected)`;
            }
            
            initializeSpeechRecognition() {
                // Check if Speech Recognition is supported
                if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                    this.speechRecognition = new SpeechRecognition();
                    
                    // Configure speech recognition
                    this.speechRecognition.continuous = true;  // Enable continuous listening
                    this.speechRecognition.interimResults = true;
                    this.speechRecognition.lang = 'en-US';
                    this.speechRecognition.maxAlternatives = 1;
                    
                    // Enhanced voice activity detection settings
                    this.lastSpeechTime = 0;
                    this.lastSignificantSpeechTime = 0;  // Track when we last had significant speech
                    this.speechTimeout = null;
                    this.silenceThreshold = 2000; // 2 seconds for speech-to-send detection
                    this.minimumSpeechLength = 8; // Minimum characters before considering significant speech
                    this.speechBuffer = '';  // Buffer to accumulate speech within a session
                    this.persistentSpeechBuffer = ''; // Persistent buffer across recognition restarts
                    this.isSignificantSpeechDetected = false;
                    this.isManualStop = false; // Track if user manually stopped
                    this.recognitionRestartCount = 0; // Track restarts
                    this.speechEvents = []; // Track speech events to detect continuous speaking
                    
                    // Event handlers
                    this.speechRecognition.onstart = () => this.onSpeechStart();
                    this.speechRecognition.onresult = (event) => this.onSpeechResult(event);
                    this.speechRecognition.onerror = (event) => this.onSpeechError(event);
                    this.speechRecognition.onend = () => this.onSpeechEnd();
                    
                } else {
                    this.updateSpeechStatus('Speech recognition not supported in this browser', 'error');
                    this.micButton.disabled = true;
                    this.micButton.title = 'Speech recognition not supported';
                }
            }
            
            toggleSpeechRecognition() {
                if (!this.speechRecognition) return;
                
                if (this.isListening) {
                    this.stopSpeechRecognition();
                } else {
                    this.startSpeechRecognition();
                }
            }
            
            startSpeechRecognition() {
                if (!this.speechRecognition || this.isListening) return;
                
                try {
                    this.speechRecognition.start();
                } catch (error) {
                    console.error('Speech recognition error:', error);
                    this.updateSpeechStatus('Failed to start speech recognition', 'error');
                }
            }
            
            stopSpeechRecognition() {
                if (!this.speechRecognition || !this.isListening) return;
                
                console.log('Manually stopping speech recognition');
                this.isManualStop = true;
                this.speechRecognition.stop();
            }
            
            onSpeechStart() {
                this.isListening = true;
                this.micButton.classList.add('listening');
                this.micButton.classList.remove('processing');
                this.micButton.querySelector('i').className = 'fas fa-microphone-slash';
                
                // Clear processing state from previous sessions
                this.speechStatus.classList.remove('processing');
                
                // Determine if this is a fresh start or continuation
                const isFreshStart = this.isManualStop || this.persistentSpeechBuffer === '';
                
                if (isFreshStart) {
                    // Fresh start - reset everything
                    this.updateSpeechStatus('Listening... Start speaking now', 'listening');
                    this.transcriptDisplay.textContent = 'Listening...';
                    this.persistentSpeechBuffer = '';
                    this.recognitionRestartCount = 0;
                    this.speechEvents = [];
                    console.log('Fresh speech recognition start');
                } else {
                    // Continuation after browser restart
                    this.recognitionRestartCount++;
                    this.updateSpeechStatus(`Continuing... (restart #${this.recognitionRestartCount})`, 'listening');
                    this.transcriptDisplay.textContent = this.persistentSpeechBuffer + ' [continuing...]';
                    console.log('Speech recognition continued (restart #' + this.recognitionRestartCount + ')');
                }
                
                this.transcriptDisplay.classList.add('active');
                this.isManualStop = false;
                
                // Reset per-session variables but preserve persistent data
                this.speechBuffer = '';
                this.isSignificantSpeechDetected = (this.persistentSpeechBuffer.length >= this.minimumSpeechLength);
                this.lastSpeechTime = Date.now();
            }
            
            onSpeechResult(event) {
                let interimTranscript = '';
                let finalTranscript = '';
                
                // Process all results from this recognition session
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                // Get the current session transcript (final has priority)
                const currentSessionTranscript = finalTranscript || interimTranscript;
                
                if (currentSessionTranscript.trim().length > 0) {
                    // Track this speech activity
                    this.trackSpeechEvent();
                    this.lastSpeechTime = Date.now();
                    
                    // CRITICAL: Always accumulate final transcripts to persistent buffer
                    if (finalTranscript.trim().length > 0) {
                        // Add final transcript to our persistent buffer
                        if (this.persistentSpeechBuffer) {
                            this.persistentSpeechBuffer += ' ' + finalTranscript.trim();
                        } else {
                            this.persistentSpeechBuffer = finalTranscript.trim();
                        }
                        console.log('Added to persistent buffer:', finalTranscript, 'Total:', this.persistentSpeechBuffer);
                    }
                    
                    // Build display transcript: persistent buffer + current interim
                    let displayTranscript = this.persistentSpeechBuffer;
                    if (interimTranscript.trim().length > 0) {
                        displayTranscript += (displayTranscript ? ' ' : '') + interimTranscript.trim();
                    }
                    
                    // Update the display ONLY if we're not currently processing a previous result
                    if (!this.speechStatus.classList.contains('processing')) {
                        this.transcriptDisplay.textContent = displayTranscript || 'Listening...';
                    }
                    
                    // Check if we have significant accumulated speech
                    if (displayTranscript.trim().length >= this.minimumSpeechLength) {
                        this.isSignificantSpeechDetected = true;
                        this.lastSignificantSpeechTime = Date.now();
                        
                        // Show we're capturing speech ONLY if not already processing
                        if (!this.speechStatus.classList.contains('processing')) {
                            const preview = displayTranscript.length > 50 ? 
                                displayTranscript.substring(0, 50) + '...' : displayTranscript;
                            this.updateSpeechStatus(`Capturing: "${preview}"`, 'listening');
                        }
                    }
                    
                    // Clear any existing timeout
                    if (this.speechTimeout) {
                        clearTimeout(this.speechTimeout);
                        this.speechTimeout = null;
                    }
                    
                    // ONLY set timeout for final results when we have significant speech
                    // AND user isn't actively continuing to speak
                    // AND we're not already processing
                    if (finalTranscript && this.isSignificantSpeechDetected && !this.speechStatus.classList.contains('processing')) {
                        // Use a longer delay and check for continued activity
                        this.speechTimeout = setTimeout(() => {
                            const timeSinceLastSpeech = Date.now() - this.lastSpeechTime;
                            const hasRecentActivity = this.isActivelySpeaking();
                            
                            // Only send if truly quiet for the full threshold period AND not currently processing
                            if (timeSinceLastSpeech >= this.silenceThreshold && !hasRecentActivity && !this.speechStatus.classList.contains('processing')) {
                                console.log('Confirmed silence - processing complete speech:', this.persistentSpeechBuffer);
                                this.processSpeechResult(this.persistentSpeechBuffer);
                            } else {
                                console.log('Still active or too recent or already processing - not sending yet');
                            }
                        }, this.silenceThreshold);
                    }
                } else {
                    // No new transcript but show what we have accumulated (if not processing)
                    if (!this.speechStatus.classList.contains('processing')) {
                        this.transcriptDisplay.textContent = this.persistentSpeechBuffer || 'Listening...';
                    }
                }
            }
            
            processSpeechResult(transcript) {
                // Validate transcript
                const cleanTranscript = transcript.trim();
                if (!cleanTranscript || cleanTranscript.length < 2) {
                    console.log('Transcript too short or empty, ignoring:', cleanTranscript);
                    this.resetSpeechUI();
                    return;
                }
                
                // Prevent double processing
                if (this.speechStatus.classList.contains('processing')) {
                    console.log('Already processing speech, ignoring duplicate');
                    return;
                }
                
                console.log('Processing complete speech result:', cleanTranscript);
                
                // Store for potential sending - PRESERVE the transcript
                this.currentTranscript = cleanTranscript;
                
                // Update UI to processing state
                this.updateSpeechStatus('Processing speech...', 'processing');
                this.micButton.classList.remove('listening');
                this.micButton.classList.add('processing');
                this.micButton.querySelector('i').className = 'fas fa-cog fa-spin';
                
                // Update display immediately to show final transcript
                this.transcriptDisplay.textContent = cleanTranscript;
                this.transcriptDisplay.classList.add('active');
                
                // Clear any pending timeouts
                if (this.speechTimeout) {
                    clearTimeout(this.speechTimeout);
                    this.speechTimeout = null;
                }
                
                // Stop current recognition to prevent interference
                if (this.isListening) {
                    console.log('Stopping recognition for processing');
                    this.isManualStop = true;
                    try {
                        this.speechRecognition.stop();
                    } catch (e) {
                        console.warn('Error stopping recognition:', e);
                    }
                }
                
                // Auto-send if enabled, otherwise prepare for manual send
                if (this.autoSendSpeech.checked) {
                    console.log('Auto-sending processed speech');
                    setTimeout(() => {
                        this.sendTranscriptAsMessage();
                        // ONLY clear buffers AFTER successful send
                        this.clearSpeechBuffers();
                    }, 300); // Brief delay for UI feedback
                } else {
                    // Manual mode - show transcript and wait for user action
                    this.transcriptDisplay.textContent = cleanTranscript;
                    this.transcriptDisplay.classList.add('active');
                    this.updateSpeechStatus('Speech ready. Click Send to submit or microphone for more input.');
                    this.resetSpeechUI();
                    // Don't clear buffers in manual mode until after send
                }
            }
            
            onSpeechError(event) {
                console.error('Speech recognition error:', event.error);
                
                let errorMessage = 'Speech recognition error';
                switch (event.error) {
                    case 'no-speech':
                        errorMessage = 'No speech detected. Try speaking again.';
                        break;
                    case 'audio-capture':
                        errorMessage = 'Microphone access denied or unavailable';
                        break;
                    case 'not-allowed':
                        errorMessage = 'Microphone permission denied';
                        break;
                    case 'network':
                        errorMessage = 'Network error during speech recognition';
                        break;
                    default:
                        errorMessage = `Speech error: ${event.error}`;
                }
                
                this.updateSpeechStatus(errorMessage, 'error');
                this.resetSpeechUI();
            }
            
            onSpeechEnd() {
                console.log('Speech recognition ended. Manual stop:', this.isManualStop, 'Persistent buffer:', this.persistentSpeechBuffer);
                this.isListening = false;
                
                // If this was a manual stop by user clicking stop button
                if (this.isManualStop) {
                    console.log('Manual stop - processing all accumulated speech');
                    
                    // Process accumulated speech if we have any and auto-send is enabled
                    if (this.persistentSpeechBuffer.trim().length > 0) {
                        if (this.autoSendSpeech.checked) {
                            console.log('Auto-sending accumulated speech on manual stop:', this.persistentSpeechBuffer);
                            this.processSpeechResult(this.persistentSpeechBuffer.trim());
                        } else {
                            // Manual send mode - just show what we captured
                            this.transcriptDisplay.textContent = this.persistentSpeechBuffer;
                            this.updateSpeechStatus('Speech captured. Click Send or microphone again.');
                            this.resetSpeechUI();
                        }
                    } else {
                        this.updateSpeechStatus('No speech captured. Click microphone to try again.');
                        this.resetSpeechUI();
                    }
                    return;
                }
                
                // This is an automatic end due to browser limitations - check if we should restart
                const timeSinceLastSpeech = Date.now() - this.lastSpeechTime;
                const hasSignificantSpeech = this.persistentSpeechBuffer.trim().length > this.minimumSpeechLength;
                const shouldRestart = hasSignificantSpeech && timeSinceLastSpeech < 3000; // Recent speech activity
                
                console.log('Auto-end evaluation:', {
                    timeSinceLastSpeech,
                    hasSignificantSpeech,
                    shouldRestart,
                    persistentBuffer: this.persistentSpeechBuffer
                });
                
                if (shouldRestart) {
                    // Browser restart due to limitations - continue listening
                    console.log('Auto-restarting due to browser limitations');
                    this.recognitionRestartCount++;
                    
                    setTimeout(() => {
                        if (!this.isListening && !this.speechStatus.classList.contains('processing')) {
                            console.log('Restarting speech recognition (restart #' + this.recognitionRestartCount + ')');
                            this.startSpeechRecognition();
                        }
                    }, 100);
                    return;
                }
                
                // Natural end - no recent activity or user stopped speaking
                console.log('Natural speech end');
                
                // If we have accumulated significant speech, process it
                if (this.persistentSpeechBuffer.trim().length >= this.minimumSpeechLength) {
                    if (this.autoSendSpeech.checked) {
                        console.log('Auto-sending accumulated speech on natural end:', this.persistentSpeechBuffer);
                        // Small delay to ensure we don't miss any final words
                        setTimeout(() => {
                            this.processSpeechResult(this.persistentSpeechBuffer.trim());
                        }, 500);
                    } else {
                        this.transcriptDisplay.textContent = this.persistentSpeechBuffer;
                        this.updateSpeechStatus('Speech captured. Click Send or microphone again.');
                    }
                } else {
                    // No significant speech captured
                    this.updateSpeechStatus('Ready for voice input');
                }
                
                this.resetSpeechUI();
                
                // Restart for continuous mode if enabled (after a delay)
                if (this.continuousListening.checked && !this.speechStatus.classList.contains('processing')) {
                    setTimeout(() => {
                        if (this.continuousListening.checked && !this.isListening) {
                            console.log('Restarting for continuous mode');
                            this.startSpeechRecognition();
                        }
                    }, 2000);
                }
            }
            
            resetSpeechUI() {
                this.micButton.classList.remove('listening', 'processing');
                this.micButton.querySelector('i').className = 'fas fa-microphone';
                
                // Clear any pending timeouts
                if (this.speechTimeout) {
                    clearTimeout(this.speechTimeout);
                    this.speechTimeout = null;
                }
                
                // Only reset display if no current transcript is being processed/shown
                if (!this.currentTranscript) {
                    this.transcriptDisplay.textContent = 'Click microphone â†’ speak â†’ pause 2 seconds to send';
                    this.transcriptDisplay.classList.remove('active');
                }
                
                // Reset speech detection variables but keep persistent buffer if we're continuing
                this.speechBuffer = '';
                this.isSignificantSpeechDetected = false;
                this.isManualStop = false;
            }
            
            sendTranscriptAsMessage() {
                if (!this.currentTranscript) return;
                
                // Set the transcript in the input field and send it
                this.chatInput.value = this.currentTranscript;
                console.log('Sending transcript as message:', this.currentTranscript);
                
                // Send the message
                this.sendMessage();
                
                // Update display to show message was sent
                this.transcriptDisplay.textContent = 'Message sent! Click microphone for next input.';
                this.transcriptDisplay.classList.remove('active');
                this.updateSpeechStatus('Ready for voice input');
            }
            
            clearSpeechBuffers() {
                // Clear all speech-related buffers and state
                this.currentTranscript = '';
                this.persistentSpeechBuffer = '';
                this.speechBuffer = '';
                this.recognitionRestartCount = 0;
                this.speechEvents = [];
                this.isSignificantSpeechDetected = false;
                
                console.log('Speech buffers cleared');
            }
            
            updateContinuousMode() {
                const isEnabled = this.continuousListening.checked;
                this.updateSpeechStatus(
                    isEnabled ? 'Continuous mode enabled - will keep listening after 2-second pause' : 'Single-shot mode - pause 2 seconds to send, or click mic'
                );
            }
            
            updateSpeechStatus(message, type = '') {
                this.speechStatus.textContent = message;
                this.speechStatus.className = `speech-status ${type}`;
                
                if (type === 'processing') {
                    this.micButton.classList.add('processing');
                } else if (type === 'error') {
                    // Show error state briefly then reset
                    setTimeout(() => {
                        if (!this.isListening) {
                            this.updateSpeechStatus('Ready for voice input');
                        }
                    }, 3000);
                }
            }
            
            // Helper method to check if user is likely still speaking
            isActivelySpeaking() {
                const now = Date.now();
                const recentWindow = 2000; // Look at last 2 seconds of activity
                const significantActivityThreshold = 3; // Need at least 3 events to consider active
                
                // Remove old events outside our window
                this.speechEvents = this.speechEvents.filter(time => now - time < recentWindow);
                
                // Check if we have recent speech events indicating continued talking
                const recentEvents = this.speechEvents.length;
                const timeSinceLastEvent = this.speechEvents.length > 0 ? now - Math.max(...this.speechEvents) : Infinity;
                
                // Consider actively speaking if:
                // 1. Multiple recent speech events AND
                // 2. Very recent activity (within 1.5 seconds)
                const isActive = recentEvents >= significantActivityThreshold && timeSinceLastEvent < 1500;
                
                if (isActive) {
                    console.log('Active speaking detected:', { recentEvents, timeSinceLastEvent });
                }
                
                return isActive;
            }
            
            // Track speech events with more context
            trackSpeechEvent() {
                const now = Date.now();
                this.speechEvents.push(now);
                
                // Keep only recent events (last 10 seconds for historical analysis)
                this.speechEvents = this.speechEvents.filter(time => now - time < 10000);
                
                // Limit array size to prevent memory issues
                if (this.speechEvents.length > 50) {
                    this.speechEvents = this.speechEvents.slice(-30);
                }
            }
            
            // Format AI response content with basic markdown-like formatting
            formatAiResponse(text) {
                // First escape HTML to prevent XSS
                let formatted = this.escapeHtml(text);
                
                // Apply formatting patterns in order
                
                // Headers (must be at start of line)
                formatted = formatted.replace(/^### (.*$)/gm, '<h3>$1</h3>');
                formatted = formatted.replace(/^## (.*$)/gm, '<h2>$1</h2>');
                formatted = formatted.replace(/^# (.*$)/gm, '<h1>$1</h1>');
                
                // Code blocks first (to avoid interfering with other patterns)
                formatted = formatted.replace(/```([\s\S]*?)```/g, '<pre><code>$1</code></pre>');
                
                // Inline code
                formatted = formatted.replace(/`([^`]+)`/g, '<code>$1</code>');
                
                // Bold and italic
                formatted = formatted.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
                formatted = formatted.replace(/\*(.*?)\*/g, '<em>$1</em>');
                
                // Blockquotes
                formatted = formatted.replace(/^> (.+$)/gm, '<blockquote>$1</blockquote>');
                
                // Lists - handle separately to avoid conflicts
                let lines = formatted.split('\n');
                let inOrderedList = false;
                let inUnorderedList = false;
                
                for (let i = 0; i < lines.length; i++) {
                    const line = lines[i].trim();
                    
                    // Check for numbered list items
                    if (/^\d+\.\s+/.test(line)) {
                        if (!inOrderedList) {
                            lines[i] = '<ol><li>' + line.replace(/^\d+\.\s+/, '') + '</li>';
                            inOrderedList = true;
                        } else {
                            lines[i] = '<li>' + line.replace(/^\d+\.\s+/, '') + '</li>';
                        }
                        inUnorderedList = false;
                    }
                    // Check for bullet list items
                    else if (/^[-*+]\s+/.test(line)) {
                        if (!inUnorderedList) {
                            lines[i] = '<ul><li>' + line.replace(/^[-*+]\s+/, '') + '</li>';
                            inUnorderedList = true;
                        } else {
                            lines[i] = '<li>' + line.replace(/^[-*+]\s+/, '') + '</li>';
                        }
                        inOrderedList = false;
                    }
                    // Not a list item
                    else {
                        if (inOrderedList) {
                            lines[i-1] = lines[i-1] + '</ol>';
                            inOrderedList = false;
                        }
                        if (inUnorderedList) {
                            lines[i-1] = lines[i-1] + '</ul>';
                            inUnorderedList = false;
                        }
                    }
                }
                
                // Close any remaining open lists
                if (inOrderedList) {
                    lines[lines.length-1] += '</ol>';
                }
                if (inUnorderedList) {
                    lines[lines.length-1] += '</ul>';
                }
                
                formatted = lines.join('\n');
                
                // Handle line breaks and paragraphs
                formatted = formatted.replace(/\n\n+/g, '</p><p>');
                formatted = formatted.replace(/\n/g, '<br>');
                
                // Wrap in paragraphs (but avoid wrapping block elements)
                if (!formatted.startsWith('<')) {
                    formatted = '<p>' + formatted + '</p>';
                } else {
                    // Add paragraph wrapping while preserving block elements
                    formatted = formatted.replace(/^([^<][^]*?)(<(?:h[1-6]|ul|ol|blockquote|pre)>)/gm, '<p>$1</p>$2');
                    formatted = formatted.replace(/(<\/(?:h[1-6]|ul|ol|blockquote|pre)>)([^<][^]*?)$/gm, '$1<p>$2</p>');
                }
                
                // Clean up empty paragraphs
                formatted = formatted.replace(/<p><\/p>/g, '');
                formatted = formatted.replace(/<p>\s*<\/p>/g, '');
                
                return formatted;
            }
            
            escapeHtml(text) {
                const div = document.createElement('div');
                div.textContent = text;
                return div.innerHTML;
            }
        }
        
        // Initialize chat when page loads
        document.addEventListener('DOMContentLoaded', () => {
            new KokoroChat();
        });
    </script>
</body>
</html>